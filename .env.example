# .env.example
# Copy this file to .env and edit values as needed.

# If set to "true" the Docker build will install optional dev dependencies
# declared under [project.optional-dependencies].dev in each package's
# pyproject.toml (for example, pytest). Default: false
INSTALL_DEV=false

# LLM Provider Configuration
# Choose between "vllm" (local inference) or "gemini" (Google Gemini)
LLM_PROVIDER=vllm

# vLLM Configuration (only needed if LLM_PROVIDER=vllm)
# VLLM_HOST=vllm-openai
# VLLM_MAIN_PORT=8000
# MODEL_PATH=/models/HuggingFaceTB--SmolLM2-1.7B-Instruct

# Google Gemini Configuration (only needed if LLM_PROVIDER=gemini)
# Get your API key from: https://aistudio.google.com/app/apikey
# GEMINI_API_KEY=your-api-key-here
# GEMINI_MODEL=gemini-2.0-flash

# Other environment variables used by the project (tokens, credentials) should
# be set in your local .env, but do NOT commit secrets to the repo.
# Example placeholders:
# HF_TOKEN=
# MONGO_ROOT_USERNAME=admin
# MONGO_ROOT_PASSWORD=example
