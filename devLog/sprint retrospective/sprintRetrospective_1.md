---
layout: default
title: Sprint 1
parent: Sprint Reviews
grand_parent: DevLog
---

# Sprint Review - Sprint 1

## Informaci√≥n General

- **Sprint:** Sprint 1
- **Fecha de inicio:** 29 de septiembre de 2025
- **Fecha de finalizaci√≥n:** 10 de octubre de 2025
- **Duraci√≥n:** 2 semanas (12 d√≠as)
- **Objetivo del Sprint:** Desarrollar un chatbot b√°sico ReAct funcional

---

## Objetivo del Sprint

Implementar un Producto M√≠nimo Viable (PMV) de un agente de IA que sirva como base para un chatbot educativo, utilizando una arquitectura ReAct (Reason-Action) con capacidad de usar herramientas y memoria a corto plazo.

---

## Incremento Alcanzado

### ‚úÖ Funcionalidades Completadas

#### 1. **Infraestructura de Inferencia (Issues #21, #22)**
- Despliegue de modelo LLM en Docker utilizando vLLM
- Configuraci√≥n del modelo Qwen2.5-1.5B-Instruct
- Optimizaci√≥n para hardware limitado (5 GB VRAM)
- Soporte para function calling

#### 2. **Agente de IA con Arquitectura ReAct (Issue #25)**
- Implementaci√≥n de `GraphAgent` usando LangGraph
- Dise√±o de estados: START, THINK, END
- Integraci√≥n con el modelo de inferencia
- Capacidad de razonamiento y selecci√≥n de acciones

#### 3. **Sistema de Memoria a Corto Plazo (Issue #26)**
- Implementaci√≥n de checkpointer para persistencia de estado
- Configuraci√≥n de base de datos para almacenamiento
- Sistema de threads para conversaciones independientes
- Seguimiento de contexto conversacional

#### 4. **Sistema de Herramientas (Issues #23, #24)**
- Definici√≥n de herramientas b√°sicas
- Integraci√≥n de herramientas en el agente
- Selecci√≥n adaptativa de herramientas seg√∫n la query del usuario

#### 5. **API Backend**
- Desarrollo de API con FastAPI (`backend/api.py`)
- Endpoints implementados:
  - `/` - Endpoint ra√≠z
  - `/health` - Estado del servicio
  - `/chat` - Interacci√≥n con el chatbot
- Documentaci√≥n de la API

#### 6. **Arquitectura de Microservicios**
- Dockerizaci√≥n del backend
- Docker Compose con 2 servicios:
  - Servicio vLLM (inferencia)
  - Servicio Backend (API)
- Comunicaci√≥n entre servicios en red interna

#### 7. **Testing**
- Suite de tests unitarios para el agente
- Tests de integraci√≥n para la API
- Tests de infraestructura
- Configuraci√≥n de pytest

#### 8. **Documentaci√≥n y Versionado**
- Implementaci√≥n de CHANGELOG siguiendo Keep a Changelog
- Versionado sem√°ntico (v0.1.0)
- GitHub Actions para releases autom√°ticas
- GitHub Pages con tema Just the Docs (v0.1.2)
- Workflow de Jekyll para generaci√≥n autom√°tica de documentaci√≥n

### üìä M√©tricas del Incremento

- **Issues completados:** 6/6 (100%)
- **Versi√≥n entregada:** v0.1.2
- **Cobertura de tests:** Implementada (unitarios, integraci√≥n, infraestructura)
- **Servicios desplegados:** 2 (vLLM + Backend)

---

## Obst√°culos Encontrados

### üöß Obst√°culos T√©cnicos

#### 1. **Limitaci√≥n de Hardware**
- **Descripci√≥n:** Disponibilidad de solo 5 GB de VRAM para el despliegue del modelo
- **Impacto:** Restricci√≥n en la selecci√≥n de modelos disponibles
- **Resoluci√≥n:** 
  - Selecci√≥n de Small Language Models (SLM)
  - Optimizaci√≥n mediante vLLM
  - Consideraci√≥n de inferencia h√≠brida (API + local) para desarrollo

#### 2. **Selecci√≥n del Modelo Adecuado**
- **Descripci√≥n:** Dificultad para encontrar un modelo que cumpliera todos los requisitos:
  - Capacidad de seguir instrucciones (instruct)
  - Fine-tuned para function calling
  - Compatible con limitaciones de hardware
- **Impacto:** Necesidad de cambiar el modelo inicialmente seleccionado
- **Resoluci√≥n:**
  - Investigaci√≥n de paper "Small Language Models for Future AI Agents"
  - Migraci√≥n a Qwen2.5-1.5B-Instruct
  - Actualizaci√≥n de configuraciones (Docker vLLM, .env, system prompt)

#### 3. **Comportamiento Inadecuado en Function Calling**
- **Descripci√≥n:** El modelo inicial no respond√≠a correctamente a la llamada de herramientas
- **Impacto:** Retraso en la implementaci√≥n de la API
- **Resoluci√≥n:**
  - Cambio a modelo Qwen2.5-1.5B-Instruct con mejor soporte
  - Ajuste de prompts del sistema
  - Validaci√≥n mediante tests

### üí° Aprendizajes

1. **Viabilidad de SLMs:** Los Small Language Models son suficientes para aplicaciones ag√©nticas en escenarios con recursos limitados
2. **Importancia de la selecci√≥n de modelo:** La elecci√≥n del modelo correcto es cr√≠tica para el function calling
3. **Testing temprano:** Implementar tests desde el inicio permite detectar problemas de integraci√≥n r√°pidamente
4. **Arquitectura de microservicios:** La separaci√≥n en contenedores facilita el desarrollo y mantenimiento

---

## Retrospectiva T√©cnica

### ‚ú® Lo que funcion√≥ bien
- Uso de LangGraph para simplificar la implementaci√≥n del agente
- Podman Compose para orquestar los servicios
- Metodolog√≠a de documentaci√≥n (Keep a Changelog + Versionado Sem√°ntico)
- Configuraci√≥n de tests automatizados desde el inicio
- GitHub Projects para seguimiento √°gil

### üîÑ √Åreas de mejora
- Planificar mejor la selecci√≥n de modelos antes de iniciar la implementaci√≥n
- Considerar limitaciones de hardware en la fase de dise√±o
- Documentaci√≥n continua durante el desarrollo (no solo al final)

---

## Demostraci√≥n del Incremento

El incremento entregado incluye:

1. **Sistema funcional end-to-end:**
   - Usuario ‚Üí API FastAPI ‚Üí GraphAgent ‚Üí vLLM ‚Üí Respuesta
   
2. **Capacidades demostradas:**
   - Conversaciones con memoria a corto plazo
   - Uso de herramientas mediante arquitectura ReAct
   - Endpoints RESTful operativos

3. **Infraestructura desplegable:**
   - `podman-compose up` levanta todo el sistema
   - Servicios independientes y escalables

---

## Pr√≥ximos Pasos

Para el siguiente sprint se consideran las siguientes mejoras:
- Expansi√≥n del conjunto de herramientas disponibles
- Optimizaci√≥n del rendimiento del modelo
- Ampliaci√≥n de la cobertura de tests

---

## Conclusi√≥n

El Sprint 1 ha sido completado exitosamente, alcanzando el objetivo de implementar un chatbot b√°sico ReAct funcional. A pesar de los obst√°culos t√©cnicos relacionados con las limitaciones de hardware y la selecci√≥n del modelo, se logr√≥ entregar un incremento de producto completamente funcional con todos los componentes esenciales: agente de IA, sistema de memoria, herramientas, API backend y arquitectura de microservicios.

El producto est√° listo para ser utilizado como base para iteraciones futuras y cumple con los criterios de aceptaci√≥n definidos en la Sprint Planning.

---

**Versi√≥n del producto:** v0.1.2  
**Estado:** ‚úÖ Completado  
**Fecha de revisi√≥n:** 11 de octubre de 2025
