---
layout: default
title: 30 Septiembre 2025
parent: Septiembre 2025
grand_parent: Daily Scrums
---

# Daily Scrum - 30 de Septiembre 2025

Ayer me dediqué a tratar de resolver los Issues #21 y #22 , es decir, a desplegar un modelo LLM (en este caso Small Language Model por su tamaño) en docker.

Esta no fue tarea fácil, ya que presentaba las siguientes deificultades:

- Limitación de Hardware, con apenas 5 GB de VRAM disponible para el modelo
- Necesidades especiales: Es necesario que el modelo pueda seguir instrucciones (tipo instruct) y tambien que es *finetuned* para el *function calling* (#22 ).

Hoy será necesario ajustar parámetros y hacer pruebas para comprobar el correcto funcionamiento del sistema.

Además, considerando la dificultad de encontrar un modelo apto, seguramente habrá que recurrir a inferencia por API para el modelo de embedding, o al contrario; tener la inferencia del modelo principal por API y el embedding desplegado.

Esto sería a modo de testing y desarrollo, ya que en producción habría que tener ambos modelos (sino más) desplegados en una máquina más potente.

Tareas de hoy:
- Ajustar parámetros
- Generar pruebas automáticas